
# 0. Установить gsutil, инструкция на оф сайте
# 1. Создаем таблицу и схороняем в нее результаты запроса
# 2. Создаем в Google Cloud Storage сегмент с настройками Regional>europe_west
# 3. Экспорт таблицы с результатами: вписываем segment_name/folder_name/* (каталог опционально)
# 4. С локальной машины выполняем  (возможно с сервака, если пробьем туда gsutil)

gsutil -m cp -R gs://bucket_name ./local_folder_name

# 5.1 В каталоге с выгрузкой склеиваем куски в полноценный csv
# 5.2 Заголовок прописывается у всех кусков - сначала нужно тереть везде первую строку, а потом уже клеить // либо sed стандартные названия колонок из BQ (возможно, не всегда)

for i in 0*; do sed -i '1d' "$i"; done # вариант №1 для пункта 5 - до конкатенации
cat 0* > file_name.csv
rm 0*
sed -i '/s_g_m/d' filename.csv # вариант №2 для пункта 5 - после конкатенации. кажется, этот быстрее

# 6. Теперь нужно сделать кошерный заголовок датасету (внимание на полноту добавляемого заголовка относительно таблицы):

cat BQdictForPythonComma.csv file_name.csv > final_file.csv

# 7. Удалить сегмент из Google Cloud Platform и/или BigQuery (если нинужон, а так можно оставить, но лучше не надо)